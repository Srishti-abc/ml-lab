# Machine Learning Laboratory Collection

A comprehensive series of hands-on machine learning exercises designed to build proficiency from basic data analysis to advanced predictive modeling. This collection features six progressively structured labs implemented as Jupyter notebooks, each focusing on core ML concepts with practical applications.

## üóÇÔ∏è Project Structure

```
ml-lab-collection/
‚îú‚îÄ‚îÄ Lab1_Data_Import_Visualization.ipynb
‚îú‚îÄ‚îÄ Lab2_Data_Cleaning_Preprocessing.ipynb
‚îú‚îÄ‚îÄ Lab3_Linear_Regression.ipynb
‚îú‚îÄ‚îÄ Lab4_Multiple_Linear_Regression.ipynb
‚îú‚îÄ‚îÄ Lab5_Logistic_Regression.ipynb
‚îú‚îÄ‚îÄ Lab6_Classification_Algorithms.ipynb
‚îú‚îÄ‚îÄ advertising.csv
‚îú‚îÄ‚îÄ data.csv
‚îú‚îÄ‚îÄ iris.csv
‚îî‚îÄ‚îÄ README.md
```

## üî¨ Laboratory Modules

### Module 1: Data Import and Visualization Techniques
**Focus:** Foundation skills in data loading and visual exploration using matplotlib

**Core Components:**
- **Histogram Analysis:** Examine numerical data distributions with `hist()` function
- **Bar Chart Creation:** Compare categorical data using `bar()` visualization
- **Pie Chart Construction:** Display proportional relationships via `pie()` charts
- **Scatter Plot Development:** Explore correlations between variables using `scatter()`

**Learning Goals:** Data import workflows, matplotlib library mastery, exploratory data analysis

### Module 2: Data Preparation and Preprocessing
**Focus:** Essential data cleaning and transformation techniques for ML readiness

**Key Operations:**
- **Data Quality Management:** Address missing values and data inconsistencies
- **Column Engineering:** Add, remove, and modify dataset columns
- **Output Variable Configuration:** Define and label target variables with `rename()`
- **Numerical Standardization:** Apply scaling techniques (`MinMaxScaler()`, `StandardScaler()`, `RobustScaler()`)
- **Categorical Data Transformation:** Convert text categories to numbers using `get_dummies()` and `LabelEncoder()`

**Learning Goals:** Data preprocessing pipelines, feature engineering, data quality assurance

### Module 3: Simple Linear Regression
**Focus:** Introduction to predictive modeling with single-variable relationships

**Core Theory:**
- Establishing linear relationships between dependent (Y) and independent (X) variables
- Understanding linear assumptions and constraints
- Optimal line fitting through data points
- Model performance assessment

**Learning Goals:** Regression fundamentals, predictive modeling basics, statistical relationships

### Module 4: Multiple Variable Linear Regression
**Focus:** Advanced regression with multiple predictor variables

**Advanced Concepts:**
- Multi-dimensional linear equations (Y = f(X1, X2, X3, ...))
- Complex parameter estimation techniques
- Feature interaction analysis
- Model complexity management

**Learning Goals:** Multi-variate analysis, advanced regression techniques, feature relationships

### Module 5: Classification with Logistic Regression
**Focus:** Binary and multi-class classification using probabilistic approaches

**Essential Elements:**
- Supervised learning for classification problems
- Probability estimation for class predictions
- Sigmoid function implementation and theory
- Key distinctions from linear regression:
  - Linear: Produces continuous numerical outputs
  - Logistic: Generates probability scores (0 to 1 range)

**Learning Goals:** Classification methodology, probability theory, sigmoid functions

### Module 6: Comparative Classification Methods
**Focus:** Implementation and evaluation of multiple classification approaches

#### Algorithm Portfolio:

**Enhanced Logistic Regression**
- Advanced probability-based classification
- Optimized sigmoid function applications
- Cross-algorithm performance comparisons

**K-Nearest Neighbors Algorithm**
- Instance-based learning approach
- Distance metric calculations for similarity
- Distribution-free classification method
- Versatile for classification and regression tasks

**Decision Tree Methods**
- Hierarchical decision-making models
- Feature-driven data partitioning
- Iterative classification refinement
- Hands-on experience with iris flower classification

**Random Forest Implementation**
- Ensemble learning with multiple decision trees
- Bootstrap sampling from training datasets
- Democratic voting for final classifications
- Enhanced accuracy through model aggregation

**Learning Goals:** Algorithm selection, ensemble methods, comparative analysis, performance optimization

## üìà Dataset Collection

Three curated datasets support diverse learning scenarios:

- **`advertising.csv`** - Commercial marketing data for regression modeling
- **`data.csv`** - Versatile dataset supporting multiple ML applications
- **`iris.csv`** - Standard botanical dataset for classification demonstrations

## ‚öôÔ∏è Technical Requirements

- Python 3.7 or higher
- Jupyter Notebook environment
- Essential Python Libraries:
  - `pandas` - Data structure manipulation
  - `numpy` - Mathematical operations
  - `matplotlib` - Plotting and visualization
  - `scikit-learn` - Machine learning toolkit
  - `seaborn` - Enhanced statistical visualization (recommended)

## üîß Setup Instructions

1. Download or clone the project:
```bash
git clone <your-repository-url>
cd ml-lab-collection
```

2. Install dependencies:
```bash
pip install pandas numpy matplotlib scikit-learn jupyter seaborn
```

3. Start Jupyter environment:
```bash
jupyter notebook
```

## üìã Recommended Learning Path

1. Begin with **Module 1** for visualization fundamentals
2. Master data preparation in **Module 2**
3. Develop regression skills through **Modules 3-4**
4. Advance to classification with **Modules 5-6**
5. Each module reinforces previous learning - sequential completion recommended

## üéØ Course Objectives

After completing this laboratory series, students will demonstrate:
- ‚úÖ Proficiency in data visualization and exploration
- ‚úÖ Expertise in data cleaning and preprocessing workflows
- ‚úÖ Understanding of linear and logistic regression principles
- ‚úÖ Hands-on experience with multiple classification algorithms
- ‚úÖ Practical application skills with real-world datasets
- ‚úÖ Solid foundation for advanced machine learning studies

## üí° Usage Notes

Each notebook contains detailed explanations, code examples, and practical exercises. Students should execute cells sequentially and experiment with parameter modifications to deepen understanding.

## üîÑ Updates and Maintenance

This collection is actively maintained with regular updates to reflect current best practices and library versions. Feedback and suggestions for improvement are welcomed.

---

**Ready to dive into machine learning? Start with Module 1! üöÄ**